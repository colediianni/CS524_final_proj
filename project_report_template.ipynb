{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS/ECE/ISyE 524 &mdash; Introduction to Optimization &mdash; Spring 2023 ###\n",
    "\n",
    "\n",
    "# Image Distance Metric: Spatially Transformed and Enhanced Pixel-wise High-dimensional Encoding (STEPHEN)   #\n",
    "\n",
    "#### Cole Dilanni  (diianni@wisc.edu)\n",
    "#### Ilay Raz (email address)\n",
    "#### Nitzan Orr   (nitzan@cs.wisc.edu)\n",
    "\n",
    "*****\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "1. [Mathematical Model](#2.-Mathematical-model)\n",
    "1. [Solution](#3.-Solution)\n",
    "1. [Results and Discussion](#4.-Results-and-discussion)\n",
    "  1. [Optional Subsection](#4.A.-Feel-free-to-add-subsections)\n",
    "1. [Conclusion](#5.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Introduction ##\n",
    "\n",
    "#### Overview\n",
    "Our project is designing an image distance metric which takes two images and finds how to warp one to best align with the other using mixed integer programming (MIP). We achieve our results by assigning each pixel binary variables which determine where in the warped image the pixel will map.\n",
    "\n",
    "Image similarity algorithms are important for many tasks such as image recognition, image retrieval, and object tracking. The most simple image distance is the pixel-wise $L_2$ distance in which two image matricies of the same size are subtracted from each other and the resulting $L_2$ is their dissimilarity. This example highlights that an image similarity algorithm should return a higher value for pairs of images considered dissiimilar and a lower value for images which are very similar/the same.\n",
    "\n",
    "One problem with a basic $L_2$ distance metric is the \"rigidness\" of the pixels. This is to say that two images are only considered similar if their values are similar and their pixel positioning matches exactly. A failure case would be a checkerboard image compared to the same image shifted right one pixel. Even though the content remains the same (there has only been a small translation), the $L_2$ distance metric would return an extremely high value since the pixel positioning does not perfectly align.\n",
    "\n",
    "#### Related Works\n",
    "A central problem in computer vision is determining the distance between images. Many previous works have tried to provide intuitively reasonable results. Noteable works include the tangent distance [(Simard, 1993)](https://proceedings.neurips.cc/paper/1992/file/26408ffa703a72e8ac0117e74ad46f33-Paper.pdf) and the Hausdorff distance [(Huttenlocher, 1993)](https://people.eecs.berkeley.edu/~malik/cs294/Huttenlocher93.pdf). However, from the image recongition point of view, they suffer from a number of technical issues. Previous works have also proposed techniques such as Historgram Intereaction similarity measures, Invariant Moments measure (similarity between edges), and Local Edge Representation measures (similartiy between image gradient boundries).  A more promising related work has been the Image Euclidean Distance (IMED) proposed by [(Li, 2008)](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1453520). It recongnizes the issue with simple $L_2$ distance measure and proposes several improvements to it. Li takes into account not just the distance between individual pixels, but also their neighborhood which results in improved performance but not generelizeable results. [(Wang 2005)](https://www.sciencedirect.com/science/article/pii/S0031320308003130) proposed an improvement to IMED, an Adaptive Image Euclidean Distance which better fits images of varying pixel intensity.\n",
    "\n",
    "#### Proposed Method\n",
    "To this end, we propose a more general $L_2$ distance metric for computer vision which allows the pixels of one image to shift in a way which best aligns with the comparison image. Our metric, which we call Spatially Transformed and Enhanced Pixel-wise High-dimensional ENcoding or STEPHEN in short,(thanks ChatGPT), is an optimziation-based solution. In our method, pixel shifts must follow certain rules when shifting an image A to best align with image B:\n",
    "- All pixels from A must map to a point in the shifted version of A\n",
    "- All pixels in B must have a corresponding value in the shifted version of A\n",
    "- Pixels cannot cross during shift ($Apixel_{left}$ cannot be further right than $Apixel_{right}$ in the final shifted version of the image)\n",
    "\n",
    "To test our algorithm, we will use the MNIST dataset (dataset for handwritten digits 0-9). This dataset is good because it's low resolution (for fast testing), and handwritten digits have the same semantic information (0-9), but are often warped compared to one another, given handwriting differences.\n",
    "\n",
    "Another way we test STEPHEN is comparing it to the output of optical flow. Optical Flow is an algorithm in computer vision which tracks the movement of pixels between consecutive and similar images. AS both methods create a flow field of pixel displacement, we show our method and discuss how it compares to optical flow.\n",
    "\n",
    "Our report is organized as follows: Section 2 is the Mathematical Model and a detailed description of the various parts of the MIP metric. Section 3 is our Julia implementation of the model, which we invite the reader to run. In section 4 we discuss the results of our method and show it's performance on a number of test cases. Further, we compare our method to optical flow. We also discuss the limitations of our method and what future opportunities exisit. Finally, in section 5 we conclude our discussion and summarize our key take-aways. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  The first few sentences should give a quick overview of the entire project. Then, elaborate with a description of the problem that will be solved, a brief history (with [citations](https://en.wikipedia.org/wiki/Citation)) of how the problem came about, why it's important/interesting, and any other interesting facts you'd like to talk about. You should address and explain where the problem data is coming from (research? the internet? synthetically generated?) Also give an outline of the rest of the report.\n",
    "\n",
    "##### This section should be 300-600 words long, and **should be accessible to a general audience** (don't assume your reader has taken the class!). Feel free to include images if you think it'll be helpful:\n",
    "\n",
    "![fixit flowchart][flow]\n",
    "\n",
    "For more help on using Markdown, see [this reference](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet).\n",
    "\n",
    "[flow]: https://s-media-cache-ak0.pinimg.com/736x/f5/75/c5/f575c53b93724808c6f0211890a54900.jpg\n",
    "\n",
    "Over the past decade in the Machine Learning field, Neural Networks have become increasingly good at a variety of tasks, including image classification and object detection. One of the parts that is “learned” by the network is the kernel, or a small visual “template” or “recipe” that lets neural networks detect certain patterns in an image. Kernels are matched against incoming images and output how closely the image matches the kernel itself. For example, a kernel that takes on the template of a circle would output higher scores when it is matched against images of wheels or the number zero. While good at pattern-matching, Kernels also function quite rigidly. A kernel looking for circular patterns would find an off-angle shot of a wheel or a messy hand-written digit “0” to be completely foreign and unknown. As such, we have devised a method to enable flexibility of kernels to morph into nearby shapes.\n",
    "\n",
    "Our method, which we call Spatially Transformed and Enhanced Pixel-wise High-dimensional ENcoding (STEPHEN), is an optimization-based image-morphing method (thanks ChatGPT). We take a source image and target image, and compute the transformation of each pixel between the two images while maintaining the visual geometry consistent. The output of the algorithm is similar to that of optical flow but rather than retroactively tracking pixels, it transforms them in the tracked direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Mathematical model ##\n",
    "\n",
    "\n",
    "The problem of finding optimal image distance metrics comes from computer vision. Our implementation of this optimization problem will make use of MIP.\n",
    "\n",
    "\n",
    "We formulate the problem as:\n",
    "Let $P$ be the set of all $(x,y)$ pixel coordinates, and $I_S$ be the source image values, and $I_T$ be the destination image, both indexed by $P$. We define $SHIFT$ to be a matrix of binary decision variables for each $(x,y)$ coordinate representing if the source pixel will be shifted by $(\\delta_x,\\delta_y)$ to match the target image.\n",
    "\n",
    "The first constraint represents the requirement that all source pixels are used at least once, the second constraint represents the requirement that all destination pixels are mapped to at least once, the third constraint requires that no pixel can map outside of the image area, and the last few constraints enforce that the relative order of the pixels is maintained: every pixel to the left of another one can not be shifted to a pixel which is to the right of the destination of the other pixel (pixels mustn't criss-cross). In our implementation, some of these constraints were combined to make the solver more efficient.\n",
    "\n",
    "The objective function tries to minimize the squared difference between the source pixels and the destination pixels in their mapped locations. There is also a term in the objective which minimizes the number of shifts being used. This was to prevent the source image from unnecessarily mapping pixels to more destination pixels than necessary, as would be the case when the entire destination area is the same value of the source pixel. We enforce this constraint by minimizing the number of pixel shifts multiplied by a small factor $\\epsilon$. $\\epsilon$ is used to allow the model to first focus on minimizing the difference between the two images and then focus on removing unnecessary shifts.\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\min_{SHIFT_{x,y, \\delta_x, \\delta_y}} &\\sum_{(x,y, \\delta_x, \\delta_y)} \\left(I_S(x,y) - I_T(x+\\delta_x,y+\\delta_y)\\right)^2 \\cdot SHIFT_{x,y,\\delta_x,\\delta_y} + \\epsilon * SHIFT_{x,y,\\delta_x,\\delta_y} \\\\\n",
    "&\\text{S.T} & \\sum_{\\delta_x,\\delta_y} SHIFT_{x,y,\\delta_x,\\delta_y} \\geq 1 && \\forall (x,y)\\in P \\\\\n",
    "&& \\sum_{P_x, P_y} SHIFT_{x,y,\\delta_x,\\delta_y} | x+\\delta_x = P_x, y+\\delta_y = P_y \\geq 1 && \\forall (P_x,P_y)\\in P \\\\\n",
    "&& SHIFT_{x,y,\\delta_x,\\delta_y} | x+\\delta_x < 1\\ or\\ x+\\delta_x > ImgSize_x\\ or\\ y+\\delta_y < 1\\ or\\ y+\\delta_y > ImgSize_y = 0 && \\forall (x, y)\\in P \\\\\n",
    "&& \\sum_{\\delta_x,\\delta_y} SHIFT_{x-\\delta_x,y-\\delta_y,\\delta_x,\\delta_y} \\geq 1 && \\forall (x,y)\\in P \\\\\n",
    "&& SHIFT_{x,y,\\delta_x,\\delta_y} > SHIFT_{x-1,y,\\delta_x+i,\\delta_y} \\forall i \\geq 2\\\\\n",
    "&& SHIFT_{x,y,\\delta_x,\\delta_y} > SHIFT_{x,y-1,\\delta_x,\\delta_y+i} \\forall i \\geq 2\\\\\n",
    "&& SHIFT_{x,y,\\delta_x,\\delta_y} > SHIFT_{x-1,y-1,\\delta_x+i,\\delta_y+j} \\forall i \\geq 2\\ or\\ j \\geq 2\\\\\n",
    "&& SHIFT_{x,y,\\delta_x,\\delta_y} > SHIFT_{x-1,y+1,\\delta_x+i,\\delta_y-j} \\forall i \\geq 2\\ or\\ j \\geq 2\\\\\n",
    "&&SHIFT_{x,y,\\delta_x,\\delta_y}\\in \\{0,1\\}\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A discussion of the modeling assumptions made in the problem (e.g. is it from physics? economics? something else?). Explain the decision variables, the constraints, and the objective function. Finally, show the optimization problem written in standard form. Discuss the model type (LP, QP, MIP, etc.). Equations should be formatted in $\\LaTeX$ within the IJulia notebook. For this section you may **assume the reader is familiar with the material covered in class**.\n",
    "\n",
    "Here is an example of an equation:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  3 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix} =\n",
    "\\begin{bmatrix} 5 \\\\ 6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And here is an example of an optimization problem in standard form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{x \\in \\mathbb{R^n}}{\\text{maximize}}\\qquad& f_0(x) \\\\\n",
    "\\text{subject to:}\\qquad& f_i(x) \\le 0 && i=1,\\dots,m\\\\\n",
    "& h_j(x) = 0 && j=1,\\dots,r\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For some quick tips on using $\\LaTeX$, see [this cheat sheet](http://users.dickinson.edu/~richesod/latex/latexcheatsheet.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Solution ##\n",
    "\n",
    "Here, you should code up your model in Julia + JuMP and solve it. Your code should be clean, easy to read, well annotated and commented, and it should compile! You are not allowed to use other programming languages or DCP packages such as `convex.jl`. **I will be running your code**. I suggest having multiple code blocks separated by text blocks that explain the various parts of your solution. You may also solve several versions of your problem with different models/assumptions.\n",
    "\n",
    "It's fine to call external packages such as `Gurobi`, but try to minimize the use of exotic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of horses is: 10.0\n",
      "The total number of donkeys is: 0.0\n",
      "The total number of goats is: 0.0\n",
      "Coin0506I Presolve 0 (-1) rows, 0 (-3) columns and 0 (-3) elements\n",
      "Clp3002W Empty problem - 0 rows, 0 columns and 0 elements\n",
      "Clp0000I Optimal - objective value 10\n",
      "Coin0511I After Postsolve, objective 10, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective 10 - 0 iterations time 0.002, Presolve 0.00\n"
     ]
    }
   ],
   "source": [
    "# this is a code block\n",
    "using JuMP, Clp\n",
    "m=Model(Clp.Optimizer)\n",
    "\n",
    "things = [:horses, :donkeys, :goats]  # these are the things \n",
    "@variable(m, x[things] >= 0)          # the quantities of each of the things (can't be negative)\n",
    "@constraint(m, sum(x) <= 10)          # we can't have any more than 10 things total\n",
    "@objective(m, Max, x[:horses])        # we want to maximize the number of horses\n",
    "optimize!(m)\n",
    "\n",
    "for i in things\n",
    "    println(\"The total number of \", i, \" is: \", value(x[i]))     # print result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to make sure your code compiles! I will be running your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Results and discussion ##\n",
    "\n",
    "Here, you display and discuss the results. Show figures, plots, images, trade-off curves, or whatever else you can think of to best illustrate your results. The discussion should explain what the results mean, and how to interpret them. You should also explain the limitations of your approach/model and how sensitive your results are to the assumptions you made.\n",
    "\n",
    "Use plots (see `PyPlot` examples from class), or you can display results in a table like this:\n",
    "\n",
    "| Tables        | Are           | Cool  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| col 3 is      | right-aligned |\\$1600 |\n",
    "| col 2 is      | centered      |  \\$12 |\n",
    "| zebra stripes | are neat      |   \\$1 |\n",
    "\n",
    "### 4.A. Feel free to add subsections\n",
    "\n",
    "#### 4.A.a. or subsubsections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Conclusion ##\n",
    "\n",
    "We have proposed STEPHEN, an optimization-based pixel transformation method that maintains visual semantic information. Our method successfully showed how optimization can be used to “massage” similar looking images which can be used in a number of ways. First, we have shown a proof of concept that this method can be used to improve digit classification. Second, STEPHEN can be used to make kernels more flexible by allowing a single kernel to take on different forms, while remaining semantically consistent. \n",
    "\n",
    "In Neural Network training, data augmentation is a widely used and respected (by some) technique that our method could aid with. In the future our method could be used to transform input images to introduce higher variation in the training data and allow networks to better generalize. Another possible future direction is… \n",
    "\n",
    "\n",
    "##### Summarize your findings and your results, and talk about at least one possible future direction; something that might be interesting to pursue as a follow-up to your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
